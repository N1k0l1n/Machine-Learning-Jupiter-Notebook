{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Linear Algebra\n",
    "\n",
    "This topic, *Intro to Linear Algebra*, is the first in the *Machine Learning Foundations* series.\n",
    "\n",
    "It is essential because linear algebra lies at the heart of most machine learning approaches and is especially predominant in deep learning, the branch of ML at the forefront of today’s artificial intelligence advances. Through the measured exposition of theory paired with interactive examples, you’ll develop an understanding of how linear algebra is used to solve for unknown values in high-dimensional spaces, thereby enabling machines to recognize patterns and make predictions.\n",
    "\n",
    "The content covered in *Intro to Linear Algebra* is itself foundational for all the other topics in the *Machine Learning Foundations* series and is especially relevant to *Linear Algebra II*.\n",
    "\n",
    "Over the course of studying this topic, you'll:\n",
    "\n",
    "- Understand the fundamentals of linear algebra, a ubiquitous approach for solving for unknowns within high-dimensional spaces.\n",
    "- Develop a geometric intuition of what’s going on beneath the hood of machine learning algorithms, including those used for deep learning.\n",
    "- Be able to more intimately grasp the details of machine learning papers as well as all of the other subjects that underlie ML, including calculus, statistics, and optimization algorithms.\n",
    "\n",
    "Note that this Jupyter notebook is not intended to stand alone. It is the companion code to a lecture or to videos from Jon Krohn's *Machine Learning Foundations* series, which offer detail on the following:\n",
    "\n",
    "## Segment 1: Data Structures for Algebra\n",
    "\n",
    "- What Linear Algebra Is\n",
    "- A Brief History of Algebra\n",
    "- Tensors\n",
    "- Scalars\n",
    "- Vectors and Vector Transposition\n",
    "- Norms and Unit Vectors\n",
    "- Basis, Orthogonal, and Orthonormal Vectors\n",
    "- Arrays in NumPy\n",
    "- Matrices\n",
    "- Tensors in TensorFlow and PyTorch\n",
    "\n",
    "## Segment 2: Common Tensor Operations\n",
    "\n",
    "- Tensor Transposition\n",
    "- Basic Tensor Arithmetic\n",
    "- Reduction\n",
    "- The Dot Product\n",
    "- Solving Linear Systems\n",
    "\n",
    "## Segment 3: Matrix Properties\n",
    "\n",
    "- The Frobenius Norm\n",
    "- Matrix Multiplication\n",
    "- Symmetric and Identity Matrices\n",
    "- Matrix Inversion\n",
    "- Diagonal Matrices\n",
    "- Orthogonal Matrices\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
