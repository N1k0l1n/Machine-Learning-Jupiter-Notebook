{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intruduction to Regression with Neural Network in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem but in our case, we are going to simplyfy it:\n",
    "predicting a numerical variable based on some other combination of variables, even shorter... predict a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Create features\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0  , 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels\n",
    "y  = np.array([3.0, 6.0, 9.0, 12.0 , 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between y  and x to get our neural network to work is:\n",
    "y == X + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a demo tesnor for our housing price prediction problem\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700]) # real house price in dollars\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape()\n",
    "output_shape = y.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn Numpy array into tensors with dtype of float32\n",
    "X = tf.cast(tf.constant(X), dtype = tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype = tf.float32)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modeling with tensorflow\n",
    "\n",
    "1. `Crate a model` - define the input and output layers, as well as the hidden layers  of a deep learning model\n",
    "2. `Compile a model` - define the loss function ( in other words, the loss function tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and eveluation metrics (in other words, what we can use to interpret the performance of our model)\n",
    "3. `Fitting a model` - leeting the model try to find patterns between features and labels (X and y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain seed\n",
    "In TensorFlow, the term \"seed\" refers to a parameter used to initialize the internal random number generator.\n",
    "Setting a seed allows you to generate random numbers in a deterministic way, meaning that if you set the same seed and execute the same code multiple times, you'll get the same sequence of random numbers.\n",
    "Seeds are commonly used in machine learning and deep learning applications for reproducibility purposes. By fixing the seed, you ensure that your experiments produce the same results each time they are run, which is crucial for debugging, testing, and comparing different models or configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Dense(1)\n",
    "])\n",
    "\n",
    "# What the above code does, it peeks a model out of keras and with the dense method does the\n",
    "# distinguishing between 1 input and 1 output, in our case the very first elemts of X and y\n",
    "# The entire tf.keras.Dense(1) its also called a hidden layer or a neuron\n",
    "# X = np.array([-7.0, -4.0, -1.0, 2.0  , 5.0, 8.0, 11.0, 14.0])\n",
    "# y  = np.array([3.0, 6.0, 9.0, 12.0 , 15.0, 18.0, 21.0, 24.0])\n",
    "# So -7.0  and 3.0\n",
    "\n",
    "#2. Compile the model\n",
    "model.compile(\n",
    "    loss = tf.keras.losser.mae, # mae is short for mean absolute error\n",
    "    optimizer = tf.keras.optimizers.SGD(),# sgd is short for STOCHASTIC (random) gradient descent,\n",
    "                                          # and this line tells the model how should imporove\n",
    "    metrics=[\"mae\"]\n",
    "    )\n",
    "# 3. Fit the model\n",
    "model.fit(X, y, epochs= 5) # epochs is the number of repetitions throughout X and y data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement of the model\n",
    "\n",
    "We can improve our model by adjusting the steps we took to create a model.\n",
    "\n",
    "1. Create a model => Here we can add more layers, increase the number of hidden units (also know as neurons) within each of those hidden layers, and change the activation function of each layer.\n",
    "2. Compaling a model => Here we might change the optimization function or perhaps \n",
    "`the learning rate` of the optimization function.\n",
    "3. Fitting a model => Here we might fit the model for more epochs (leave it training for longer) or give it more data ( give the model more data to train for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets rebuild our model\n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model ( this time we gonna train it for longer)\n",
    "model.fit(X, y , epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recap the data\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0  , 5.0, 8.0, 11.0, 14.0])\n",
    "y  = np.array([3.0, 6.0, 9.0, 12.0 , 15.0, 18.0, 21.0, 24.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to make a prediction for a new value in the x array, and see if the model has improved\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Ways to Improve a Deep Learning Model\n",
    "\n",
    "* Adding Layers\n",
    "* Increasing the number of hidden Units\n",
    "* Change the activation function\n",
    "* Change the optimization function\n",
    "* Change the learning rate (the best thing to do)\n",
    "* Fitting on more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make an other change to improve the model\n",
    "\n",
    "# 1. Create the model by improving the hidden layers with 100 hidden units\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = \"relu\")\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model ( this time we gonna train it for longer)\n",
    "model.fit(X, y , epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrying\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0  , 5.0, 8.0, 11.0, 14.0])\n",
    "y  = np.array([3.0, 6.0, 9.0, 12.0 , 15.0, 18.0, 21.0, 24.0])\n",
    "model.predict([17.0])\n",
    "\n",
    "# In this case we have a overfitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Improvements\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation = None)\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# This model performs much better than the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Improvements\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.Adam(), # change from  SGD to Adam\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# This model performs worse than the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Improvements\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.Adam(lr= 0.01), # Adam learning rate by default is 0.001\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "#Lr is the best parameter for the job\n",
    "# This is the best model do far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "In practice, a typical workflow you'll go through when building neural networks is:\n",
    "\n",
    "1. Build a Model\n",
    "2. Fit it\n",
    "3. Evaluate it\n",
    "4. Tweeak it\n",
    "5. Fit it\n",
    "6. Evaluate it\n",
    "7. Tweeak it\n",
    "8. Fit it\n",
    "9. Evaluate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it Comes to the evaluation proccess , there are 3 words that you should memorize:\n",
    "\n",
    "> `Visualization, visualization, visualization `\n",
    "\n",
    "its a good idea to visualize: \n",
    "* The data - what data are we working with? What does it look?\n",
    "* The model itself - what does our model look like?\n",
    "* The training of a model - how does a model perform while it learns?\n",
    "* The prediction of the model - how does the predictions of a model line up against the ground truth (the original labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a bigger  dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make labels for the dataset\n",
    "y = X + 10\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Notes\n",
    "\n",
    "Tipically in a day to day work basis, you are not going to fit and evaluate on the same dataset.\n",
    "Instead , when you are actually working with ml, you should have 2 sets of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 3 Sets of Data\n",
    "\n",
    "* `The training Set` - the model learns from this data, which is typically 70-80% of the total data that you have available\n",
    "* `The Validation Set` - the model gets tuned on this data, which is typically 10- to 15% of the total data available\n",
    "* `The Test Set` - the model gets evaluated on this data, what is has learned, this set is typically  10-15% of the total data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of how many samples we have\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train = X[:40] # first 40 samples are training samples (80% of the data available)\n",
    "y_train = y[:40] \n",
    "\n",
    "X_test = X[40:] # the last 10  testing samples (50 samples in total) (20% of the data available)\n",
    "y_test = y[40:] \n",
    "\n",
    "len(X_train), len(X_test), len(y_train), length(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualization of data , split into training and test sets\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "#Plot traing data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training Data\")\n",
    "\n",
    "\n",
    "#Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing Data\")\n",
    "\n",
    "# Show a legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets build a Neural Network for our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1) # tipically they are able to autodetect the input shape, but sometimes u need to manually define it\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss = tf.keras.layers.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(X_train, y_train, epochs =100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model that builds automatically by defing the input_shape argument in the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model that builds automatically by defing the input_shape argument \n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#Create a model the same as above\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1,input_shape=[1], name = \"output_layer\"), # input_shape = [1] means that for 1 input we are after 1 output\n",
    "    tf.keras.layers.Dense(1,name = \"output_layer\")\n",
    "], name = \"model_1\")\n",
    "\n",
    "# 2. Compile a model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.kers.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() #shows the layers, the output shape and athe number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Dense` in tensorflow, means that is fully connected, meaning that all the laeyers are fully connected with the other layers\n",
    "* `Total params`, are the total number of parameters in the model\n",
    "* `Trainable parameters` - these are the parameters (patterns) the model can update as it trains\n",
    "* `Non-trainable parameters` - these parameters are not updated during training (this is tipical when you bring in already learned patterns or parameters from other models during **transfer learning**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fit our model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model = model, show_shapes = True) # you can understand the formula neeed to predict x , to y here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the model predictions\n",
    "\n",
    "To visualize the model predictions , its a good idea to plot them against the ground truth labaels.\n",
    "\n",
    "Often you'll see this in the form of `y_test` and `y_true` versus `y_pred` (ground truth vs your model predictions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred\n",
    "\n",
    "# Compare to\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Note :` If you feel like you need to reuse some kind of functionality in the future, its a good idea to turn it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets create a plotting function\n",
    "def plot_predictions(train_data = X_train,\n",
    "                     train_labels = y_train,\n",
    "                     test_data = X_test,\n",
    "                     test_labels = y_test,\n",
    "                     predictions = y_pred): \n",
    "    \"\"\"Plots train and test data, and compares predictions to the ground truth labels.\"\"\"\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "#Plot traing data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training Data\")\n",
    "\n",
    "\n",
    "#Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing Data\")\n",
    "\n",
    "#Plot model predictions\n",
    "plt.scatter(test_data, predictions, c=\"g\", label=\"Predictions\")\n",
    "\n",
    "# Show a legend\n",
    "plt.legend()\n",
    "\n",
    "plot_predictions(train_data = X_train,\n",
    "                     train_labels = y_train,\n",
    "                     test_data = X_test,\n",
    "                     test_labels = y_test,\n",
    "                     predictions = y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate predictions with regression evaluation metrics\n",
    "\n",
    "Depending on the problem you are working with, there will be different evaluation metrics to evaluate your model performance.\n",
    "\n",
    "Since we are working on a regression model,two of the main metrics:\n",
    "\n",
    "* MAE - mean absolute error, \"on avarage, how wrong is each of my models predictions\"\n",
    "* MSE - mean square error, \"square the avarage errors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MAE\n",
    "mae = tf.metrics.mean_absolute_error(y_true = y_test,\n",
    "                                     y_pred = tf.squeeze(y_pred))\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the MSE\n",
    "mse = tf.metrics.mean_squared_error(y_true = y_test, y_pred = tf.squeeze(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some function to reuse MAE and MSE\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred=tf.squeeze(y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_true, y_pred=tf.squeeze(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets create an experiment with 3 models\n",
    "1. Model 1 - same as original model, 1 layer, training for 100  epochs.\n",
    "2. Model 2 - 2 layers, training for 100 epochs\n",
    "3. Model 3 - 2 layers, training for 500 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 2.Compile the model\n",
    "model_1.compile(loss = tf.keras.layers.mae,\n",
    "                optimizer = tf.keras.optimizers.SGD(),\n",
    "                metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_1.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions and plot them for model_1\n",
    "y_preds_1 = model_1.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model_1_evaluation metrics\n",
    "mae_1 = (y_test, y_preds_1)\n",
    "mse_1 = mse(y_test, y_preds_1)\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 2.Compile the model\n",
    "model_2.compile(loss = tf.keras.layers.mae,\n",
    "                optimizer = tf.keras.optimizers.SGD(),\n",
    "                metrics = [\"mse\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_2.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and plot predictions of model 2\n",
    "y_preds_2 = model_2.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model_2_evaluation metrics\n",
    "mae_2 = (y_test, y_preds_2)\n",
    "mse_2 = mse(y_test, y_preds_2)\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "# 2.Compile the model\n",
    "model_3.compile(loss = tf.keras.layers.mae,\n",
    "                optimizer = tf.keras.optimizers.SGD(),\n",
    "                metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model_3.fit(X_train, y_train, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and plot predictions of model 3\n",
    "#Models overfits\n",
    "y_preds_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions=y_preds_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate model_3_evaluation metrics\n",
    "mae_3 = (y_test, y_preds_3)\n",
    "mse_3 = mse(y_test, y_preds_3)\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the results of the 3 experiments\n",
    "\n",
    "`Note`: you want to start with small experiments (small models) and make sure they work and then increase their scale when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets compare our models results using pandas dataframe\n",
    "import pandas as pd\n",
    "\n",
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
    "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "all_results = pd.DataFrame(model_results, columns = [\"model\", \"mae\", \"mse\"])\n",
    "all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking your Expeiments\n",
    "\n",
    "One really good habit in ML modeling is to keep track of your expeiments. And by doing so, it can be tedius if you are running lots of experiments.\n",
    "\n",
    "Luckily, there are tools to help us!\n",
    "\n",
    "* `TensorBoard` - a component of the Tensorflow library that tracks modelling experiments\n",
    "* `Weights & Biases` - a tool for tracking all kinds of ML experiments (combinated with tensorboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Our Models\n",
    "\n",
    "Saving our models allows us to use them outside of Google Colab (or whatever they were  trained) such as in a web application or mobile app.\n",
    "\n",
    "In tensorflow there are 2 major ways to save your models:\n",
    "\n",
    "1. `SavedModel format` - this is another way to serialize models. Models saved in this format can be restored using tf.keras.load_model\n",
    "2. `HDF5 models` - provided by keras as a basic save format using the HDF5 standad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_2.save(\"best_model_saved_so_far\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model on HDF5 format\n",
    "model_2.save(\"best_model_HDF5.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the SavedModel format model\n",
    "loaded_SavedModel_format = tf.keras.models.load_model(\"/content/best_model_HDF5\") # THis can be only applied on Colab, where the path of the saved model is passed as a string\n",
    "loaded_SavedModel_format.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model_2 predictions with SavedModel format predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(X_test)\n",
    "model_2_preds == loaded_SavedModel_format_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a model in H5 format\n",
    "loaded_h5_model = tf.keras.models.load_model(\"/content/best_model_HDF5.h5\")\n",
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model_2 predictions with SavedModel format predictions\n",
    "model_2_preds = model_2.predict(X_test)\n",
    "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
    "model_2_preds == loaded_h5_model_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
