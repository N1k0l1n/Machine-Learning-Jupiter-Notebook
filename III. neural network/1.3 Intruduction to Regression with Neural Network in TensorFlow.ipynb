{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intruduction to Regression with Neural Network in TensorFlow\n",
    "\n",
    "There are many definitions for a regression problem but in our case, we are going to simplyfy it:\n",
    "predicting a numerical variable based on some other combination of variables, even shorter... predict a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data to view and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Create features\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0  , 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# Create labels\n",
    "y  = np.array([3.0, 6.0, 9.0, 12.0 , 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# Visualize it\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The relationship between y  and x to get our neural network to work is:\n",
    "y == X + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a demo tesnor for our housing price prediction problem\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700]) # real house price in dollars\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape()\n",
    "output_shape = y.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn Numpy array into tensors with dtype of float32\n",
    "X = tf.cast(tf.constant(X), dtype = tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype = tf.float32)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modeling with tensorflow\n",
    "\n",
    "1. `Crate a model` - define the input and output layers, as well as the hidden layers  of a deep learning model\n",
    "2. `Compile a model` - define the loss function ( in other words, the loss function tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and eveluation metrics (in other words, what we can use to interpret the performance of our model)\n",
    "3. `Fitting a model` - leeting the model try to find patterns between features and labels (X and y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain seed\n",
    "In TensorFlow, the term \"seed\" refers to a parameter used to initialize the internal random number generator.\n",
    "Setting a seed allows you to generate random numbers in a deterministic way, meaning that if you set the same seed and execute the same code multiple times, you'll get the same sequence of random numbers.\n",
    "Seeds are commonly used in machine learning and deep learning applications for reproducibility purposes. By fixing the seed, you ensure that your experiments produce the same results each time they are run, which is crucial for debugging, testing, and comparing different models or configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model using the Sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Dense(1)\n",
    "])\n",
    "\n",
    "# What the above code does, it peeks a model out of keras and with the dense method does the\n",
    "# distinguishing between 1 input and 1 output, in our case the very first elemts of X and y\n",
    "# The entire tf.keras.Dense(1) its also called a hidden layer or a neuron\n",
    "# X = np.array([-7.0, -4.0, -1.0, 2.0  , 5.0, 8.0, 11.0, 14.0])\n",
    "# y  = np.array([3.0, 6.0, 9.0, 12.0 , 15.0, 18.0, 21.0, 24.0])\n",
    "# So -7.0  and 3.0\n",
    "\n",
    "#2. Compile the model\n",
    "model.compile(\n",
    "    loss = tf.keras.losser.mae, # mae is short for mean absolute error\n",
    "    optimizer = tf.keras.optimizers.SGD(),# sgd is short for STOCHASTIC (random) gradient descent,\n",
    "                                          # and this line tells the model how should imporove\n",
    "    metrics=[\"mae\"]\n",
    "    )\n",
    "# 3. Fit the model\n",
    "model.fit(X, y, epochs= 5) # epochs is the number of repetitions throughout X and y data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvement of the model\n",
    "\n",
    "We can improve our model by adjusting the steps we took to create a model.\n",
    "\n",
    "1. Create a model => Here we can add more layers, increase the number of hidden units (also know as neurons) within each of those hidden layers, and change the activation function of each layer.\n",
    "2. Compaling a model => Here we might change the optimization function or perhaps \n",
    "`the learning rate` of the optimization function.\n",
    "3. Fitting a model => Here we might fit the model for more epochs (leave it training for longer) or give it more data ( give the model more data to train for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets rebuild our model\n",
    "\n",
    "# 1. Create the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model ( this time we gonna train it for longer)\n",
    "model.fit(X, y , epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recap the data\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0  , 5.0, 8.0, 11.0, 14.0])\n",
    "y  = np.array([3.0, 6.0, 9.0, 12.0 , 15.0, 18.0, 21.0, 24.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to make a prediction for a new value in the x array, and see if the model has improved\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Ways to Improve a Deep Learning Model\n",
    "\n",
    "* Adding Layers\n",
    "* Increasing the number of hidden Units\n",
    "* Change the activation function\n",
    "* Change the optimization function\n",
    "* Change the learning rate (the best thing to do)\n",
    "* Fitting on more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make an other change to improve the model\n",
    "\n",
    "# 1. Create the model by improving the hidden layers with 100 hidden units\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation = \"relu\")\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model ( this time we gonna train it for longer)\n",
    "model.fit(X, y , epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrying\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0  , 5.0, 8.0, 11.0, 14.0])\n",
    "y  = np.array([3.0, 6.0, 9.0, 12.0 , 15.0, 18.0, 21.0, 24.0])\n",
    "model.predict([17.0])\n",
    "\n",
    "# In this case we have a overfitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Improvements\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation = None)\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# This model performs much better than the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Improvements\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.Adam(), # change from  SGD to Adam\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# This model performs worse than the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Improvements\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.Adam(lr= 0.01), # Adam learning rate by default is 0.001\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "#Lr is the best parameter for the job\n",
    "# This is the best model do far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a model\n",
    "\n",
    "In practice, a typical workflow you'll go through when building neural networks is:\n",
    "\n",
    "1. Build a Model\n",
    "2. Fit it\n",
    "3. Evaluate it\n",
    "4. Tweeak it\n",
    "5. Fit it\n",
    "6. Evaluate it\n",
    "7. Tweeak it\n",
    "8. Fit it\n",
    "9. Evaluate it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it Comes to the evaluation proccess , there are 3 words that you should memorize:\n",
    "\n",
    "> `Visualization, visualization, visualization `\n",
    "\n",
    "its a good idea to visualize: \n",
    "* The data - what data are we working with? What does it look?\n",
    "* The model itself - what does our model look like?\n",
    "* The training of a model - how does a model perform while it learns?\n",
    "* The prediction of the model - how does the predictions of a model line up against the ground truth (the original labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a bigger  dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make labels for the dataset\n",
    "y = X + 10\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Notes\n",
    "\n",
    "Tipically in a day to day work basis, you are not going to fit and evaluate on the same dataset.\n",
    "Instead , when you are actually working with ml, you should have 2 sets of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The 3 Sets of Data\n",
    "\n",
    "* `The training Set` - the model learns from this data, which is typically 70-80% of the total data that you have available\n",
    "* `The Validation Set` - the model gets tuned on this data, which is typically 10- to 15% of the total data available\n",
    "* `The Test Set` - the model gets evaluated on this data, what is has learned, this set is typically  10-15% of the total data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of how many samples we have\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train = X[:40] # first 40 samples are training samples (80% of the data available)\n",
    "y_train = y[:40] \n",
    "\n",
    "X_test = X[40:] # the last 10  testing samples (50 samples in total) (20% of the data available)\n",
    "y_test = y[40:] \n",
    "\n",
    "len(X_train), len(X_test), len(y_train), length(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vizualization of data , split into training and test sets\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "#Plot traing data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label=\"Training Data\")\n",
    "\n",
    "\n",
    "#Plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing Data\")\n",
    "\n",
    "# Show a legend\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets build a Neural Network for our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1) # tipically they are able to autodetect the input shape, but sometimes u need to manually define it\n",
    "])\n",
    "\n",
    "# 2. Compile the model\n",
    "model.compile(loss = tf.keras.layers.mae,\n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# 3. Fit the model\n",
    "model.fit(X_train, y_train, epochs =100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a model that builds automatically by defing the input_shape argument in the first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a model that builds automatically by defing the input_shape argument \n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#Create a model the same as above\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1,input_shape=[1], name = \"output_layer\"), # input_shape = [1] means that for 1 input we are after 1 output\n",
    "    tf.keras.layers.Dense(1,name = \"output_layer\")\n",
    "], name = \"model_1\")\n",
    "\n",
    "# 2. Compile a model\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "              optimizer = tf.kers.optimizers.SGD(),\n",
    "              metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() #shows the layers, the output shape and athe number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Dense` in tensorflow, means that is fully connected, meaning that all the laeyers are fully connected with the other layers\n",
    "* `Total params`, are the total number of parameters in the model\n",
    "* `Trainable parameters` - these are the parameters (patterns) the model can update as it trains\n",
    "* `Non-trainable parameters` - these parameters are not updated during training (this is tipical when you bring in already learned patterns or parameters from other models during **transfer learning**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fit our model to the training data\n",
    "model.fit(X_train, y_train, epochs=100, verbose=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model = model, show_shapes = True) # you can understand the formula neeed to predict x , to y here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
