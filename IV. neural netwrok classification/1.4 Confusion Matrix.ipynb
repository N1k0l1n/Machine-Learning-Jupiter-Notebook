{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confuison Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `True positive` = in binary classification, when the model should predict 1 and the truth is 1\n",
    "* `True negative` = in binary classification, when the model should predict 0 and the truth is 0\n",
    "* `False positive` = in binary classification, when the model should predict 1 and the truth is 0\n",
    "* `False negative` = in binary classification, when the model should predict 0 and the truth is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# Make 1000 examples\n",
    "n_samples = 1000\n",
    "\n",
    "# Create circles\n",
    "X, y = make_circles(n_samples,\n",
    "                    noise=0.03,\n",
    "                    random_state=42)\n",
    "\n",
    "# Slipt into training data and test data\n",
    "X_train, y_train = X[:800], y[:800]\n",
    "X_test, y_test = X[800:], y[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set the random seed\n",
    "tf.ramdom.seed(42)\n",
    "\n",
    "# 1.Create the model usingthe Sequential API\n",
    "model_1 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "#2. Compile the model\n",
    "model_1.compile(loss= \"binary_crossentropy\",\n",
    "                optimizers=tf.keras.optimizers.Adam(lr=0.02),\n",
    "                matrics=[\"accuracy\"])\n",
    "\n",
    "# 3. FIt the model\n",
    "model_1.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Make predictions\n",
    "y_preds =  model_1.predict(X_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our predictions array has come out in prediction propability form. The standard output from the sigmoid (or softmax) activation functions. So now we should convert them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predictions probabilities to binary format and view the first 10\n",
    "tf.round(y_preds)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "confusion_matrix(y_test, tf.round(y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now will prettify the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "figsize = (10, 10)\n",
    "\n",
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, tf.round(y_preds))\n",
    "cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "n_classes = cm.shape[0]\n",
    "\n",
    "# Lets prettify it\n",
    "fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "# Create a matrix plot\n",
    "cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Create classes\n",
    "classes = False\n",
    "\n",
    "if classes:\n",
    "    labels = classes\n",
    "else:\n",
    "    labels = np.arange(cm.shape[0])\n",
    "\n",
    "# Label the axis\n",
    "ax.set(title=\"Confusion Matrix\",\n",
    "       xlabel=\"Predicted Label\",\n",
    "       ylabel=\"True Label\",\n",
    "       xticks =np.arange(n_classes),\n",
    "       yticks =np.arange(n_classes),\n",
    "       xticklabels = labels,\n",
    "       yticklabels = labels)\n",
    "\n",
    "#Set x-axis labels to the bottom\n",
    "ax.xaxis.set_label_position(\"bottom\")\n",
    "ax.xaxis.set_tick_bottom()\n",
    "\n",
    "# Adjust label size \n",
    "ax.xaxis.label.set_size(20)\n",
    "ax.yaxis.label.set_size(20)\n",
    "ax.title.set_size(20)\n",
    "\n",
    "# Set the threshold for different colors\n",
    "threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "# Plot the text on each cell\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i,j]*100:.1f}%)\",\n",
    "    horizontalalignment=\"center\",\n",
    "    color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "    size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with a larger Example (Multiclass Classification)\n",
    "\n",
    "When you have more than two classes as an option, its known as `multiclass classification`.\n",
    "\n",
    "* This means if you have 3 different classes, its multiclass classification.\n",
    "* It also means that if you have 100 different classes its `multiclass classification`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To practice multiclass classification, we are going to build a neural network to classify images of different items of clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# The data has already been sorted into training and testing for us\n",
    "(train_data, train_labels), (test_data, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first training example\n",
    "print(f\"Training sample:\\n{train_data[0]}\\n\")\n",
    "print(f\"Training label:\\n{train_labels[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of a single example\n",
    "train_data[0].shape, train_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a single sample\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imread(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out samples label\n",
    "train_labels[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small list so we can index into our training labels so they are human-readable\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankele boot\"]\n",
    "\n",
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot an example image and its labels\n",
    "index_of_choise = 2000\n",
    "plt.imshow(train_data[index_of_choise], cmap=plt.cm.binary)\n",
    "plt.title(class_names[train_labels[index_of_choise]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot multiple random images of fashion MNIST\n",
    "import random\n",
    "plt.figure(figsize=(7,7))\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(2, 2, i+1)\n",
    "    rand_index = random.choise(range(len(train_data)))\n",
    "    plt.imshow(train_data[rand_index], cmap=plt.cm.binary)\n",
    "    plt.title(class_names[train_labels[rand_index]])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a multiclass classification model\n",
    "\n",
    "For our multiclass classification model, we can use a simialar architecture to our binary classifiers, however we are going to have to tweak a few things:\n",
    "\n",
    "* Input shape = 28x28 (the shape of one image)\n",
    "* Output shape = 10 (one per class of clothing)\n",
    "* Loss function = tf.keras.losses.CategoricalCrossentropy()\n",
    "    * If your labels are one-hot encoded use CategoricalCrossentropy()\n",
    "    * If your labels are intiger form use SparseCategoricalCrossentropy()\n",
    "* Output layer activation = Softmax (not Sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `Flatten` = flatten the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUR data needs to be flattened from 28*28 to 784\n",
    "flatten_model= tf.keras.Sequential([tf.keras.layers.Flatten(input_shape=(28,28))])\n",
    "flatten_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_2 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation=tf.keras.activations.softamax),\n",
    "])\n",
    "\n",
    "#2. Compile the model\n",
    "model_2.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizers=tf.keras.optimizers.Adam(),\n",
    "                matrics=[\"accuracy\"])\n",
    "\n",
    "# 3. FIt the model\n",
    "non_norm_history = model_2.fit(train_data, train_labels, epochs=10, validation_data=(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model summary\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the min and the max values of the training data\n",
    "train_data.min(), train_data.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks prefer data to be scaled (or normalized), this means they like to have the numbers in the tensors they try to find patterns between 0 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can get our training and testing data between 0 & 1 by dividing by the maximum\n",
    "train_data_norm = train_data/255.0\n",
    "test_data_norm = test_data/255.0\n",
    "\n",
    "#Check the min and max values of the scaled training data\n",
    "train_data_norm.min(), train_data_norm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that our data is normalized , lets build a model to find patterns in it\n",
    "\n",
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_3 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation=tf.keras.activations.softamax),\n",
    "])\n",
    "\n",
    "#2. Compile the model\n",
    "model_3.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizers=tf.keras.optimizers.Adam(),\n",
    "                matrics=[\"accuracy\"])\n",
    "\n",
    "# 3. FIt the model\n",
    "norm_history = model_3.fit(train_data_norm, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the loss curves between the 2 models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Plot non normalized data loss curves\n",
    "pd.DataFrame(non_norm_history.history).plot(title=\"Non normalized data\")\n",
    "# Plot normalized data loss curves\n",
    "pd.DataFrame(norm_history.history).plot(title=\"Normalized data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note : The same model with slightly different data can produce dramatically different results. So when you are comparing the models, its important to make sure that you are comparing them on the same criteria (e.g. same architecture but different data or same data but different architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the ideal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_4 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation=tf.keras.activations.softamax),\n",
    "])\n",
    "\n",
    "#2. Compile the model\n",
    "model_4.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizers=tf.keras.optimizers.Adam(),\n",
    "                matrics=[\"accuracy\"])\n",
    "\n",
    "# Create the learning rate callback\n",
    "lr_scheduler = tf.keras.callback.LearningRateScheduler(lambda epoch: 1e-3 * 10** (epoch/20))\n",
    "\n",
    "# 3. FIt the model\n",
    "find_lr_history = model_4.fit(train_data_norm, \n",
    "                              train_labels, \n",
    "                              epochs=40, \n",
    "                              validation_data=(test_data_norm, test_labels), \n",
    "                              callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning rate decay curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "lrs = 1e-3 * (10**(tf.range(40)/20))\n",
    "plt.semilogx(lrs, find_lr_history.history[\"loss\"])\n",
    "plt.xlabel(\"Learning Rate\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Finding the ideal learning rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets refit our model with the ideal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create the model\n",
    "model_4 = tf.keras.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(4, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation=tf.keras.activations.softamax),\n",
    "])\n",
    "\n",
    "#2. Compile the model\n",
    "model_4.compile(loss= tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                optimizers=tf.keras.optimizers.Adam(lr=0.001),\n",
    "                matrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "# 3. FIt the model\n",
    "find_lr_history = model_4.fit(train_data_norm, \n",
    "                              train_labels, \n",
    "                              epochs=40, \n",
    "                              validation_data=(test_data_norm, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our multi-class classification model\n",
    "\n",
    "To evaluate our multi-class classification model we could:\n",
    "* Evaluate its performance using other classification metrics\n",
    "(such as confusion matrix)\n",
    "* Asses some of its predictions (through visualization)\n",
    "*Imporove its results (by traing it for longer or changing the architecture)\n",
    "* Save amd export it to use in an application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15):\n",
    "    # Create the confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "    n_classes = cm.shape[0]\n",
    "\n",
    "    # Lets prettify it\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Create a matrix plot\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues)\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set labels to be classes\n",
    "    if classes:\n",
    "        labels = classes\n",
    "    else:\n",
    "        labels = np.arange(cm.shape[0])\n",
    "\n",
    "    # Label the axis\n",
    "    ax.set(title=\"Confusion Matrix\",\n",
    "           xlabel=\"Predicted Label\",\n",
    "           ylabel=\"True Label\",\n",
    "           xticks=np.arange(n_classes),\n",
    "           yticks=np.arange(n_classes),\n",
    "           xticklabels=labels,\n",
    "           yticklabels=labels)\n",
    "\n",
    "    # Set x-axis labels to the bottom\n",
    "    ax.xaxis.set_label_position(\"bottom\")\n",
    "    ax.xaxis.set_tick_bottom()\n",
    "\n",
    "    # Adjust label size\n",
    "    ax.xaxis.label.set_size(text_size)\n",
    "    ax.yaxis.label.set_size(text_size)\n",
    "    ax.title.set_size(text_size)\n",
    "\n",
    "    # Set the threshold for different colors\n",
    "    threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "    # Plot the text on each cell\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i,j]*100:.1f}%)\",\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "                 size=text_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions with our model\n",
    "y_probs = model_4.predict(test_data_norm)\n",
    "\n",
    "# View the first 5 predictions\n",
    "y_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probs[0], tf.argmax(y_probs[0]), class_names[tf.argmax(y_probs[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the predictions probabilities to initgers\n",
    "y_preds = y_probs.argmax(axis = 1)\n",
    "\n",
    "# View the 10 predictions labels\n",
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true=test_labels,\n",
    "                 y_pred=y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prettier confusion matrix\n",
    "make_confusion_matrix(y_true=test_labels,\n",
    "                      y_pred=y_preds,\n",
    "                      classes=class_names,\n",
    "                      figsize=(15,15),\n",
    "                      text_size=10)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
