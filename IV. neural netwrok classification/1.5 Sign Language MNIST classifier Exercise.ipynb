{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class Classification Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to this assignment! In this exercise, you will get a chance to work on a multi-class classification problem. You will be using the Sign Language MNIST dataset, which contains 28x28 images of hands depicting the 26 letters of the english alphabet.\n",
    "\n",
    "You will need to pre-process the data so that it can be fed into your `convolutional neural network` to correctly classify each image as the letter it represents.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note : For convolutional neural network see next chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, Markdown\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from time import perf_counter\n",
    "import seaborn as sns\n",
    "\n",
    "def printmd(string):\n",
    "    # Print with Markdowns    \n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('https://raw.githubusercontent.com/gchilingaryan/Sign-Language/master/sign_mnist_train.csv')\n",
    "test_df = pd.read_csv('https://raw.githubusercontent.com/gchilingaryan/Sign-Language/master/sign_mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename label into Label\n",
    "train_df.rename(columns={'label':'Label'},inplace = True)\n",
    "test_df.rename(columns={'label':'Label'},inplace = True)\n",
    "\n",
    "# Shuffle\n",
    "train_df = train_df.sample(frac = 1.0).reset_index(drop = True)\n",
    "test_df = test_df.sample(frac = 1.0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first lines\n",
    "train_df.iloc[:4,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printmd(f'### Number of images in the training set: {train_df.shape[0]}')\n",
    "printmd(f'### Number of images in the test set: {test_df.shape[0]}')\n",
    "\n",
    "d = int((train_df.shape[1] - 1)**0.5)\n",
    "printmd(f'### Shape of the images: {d} x {d}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_image(array, label = True):\n",
    "    # Reshape an array into an image format\n",
    "    array = np.array(array)\n",
    "    start_idx = 1 if label else 0\n",
    "    return array[start_idx:].reshape(28,28).astype(float)\n",
    "        \n",
    "# Display one image\n",
    "img = to_image(train_df.iloc[0])\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The labels are coded in numbers. \n",
    "# Create a mapping to get the letters corresponding to the numbers\n",
    "alphab = 'abcdefghijklmnopqrstuvwxyz'\n",
    "mapping_letter = {}\n",
    "\n",
    "for i,l in enumerate(alphab):\n",
    "    mapping_letter[l] = i\n",
    "mapping_letter = {v:k for k,v in mapping_letter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some pictures of the dataset\n",
    "fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(15, 10),\n",
    "                        subplot_kw={'xticks': [], 'yticks': []})\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = to_image(train_df.iloc[i])\n",
    "    ax.imshow(img, cmap = 'gray')\n",
    "    title = mapping_letter[train_df.Label[i]]\n",
    "    ax.set_title(title, fontsize = 15)\n",
    "plt.tight_layout(pad=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of pictures of each letter\n",
    "vc = train_df['Label'].value_counts()\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.barplot(x = sorted(vc.index), y = vc, palette = \"rocket\")\n",
    "plt.title(\"Number of pictures of each category\", fontsize = 15)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data and create the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_original = train_df.copy()\n",
    "\n",
    "# Split into training, test and validation sets\n",
    "val_index = int(train_df.shape[0]*0.1)\n",
    "\n",
    "train_df = train_df_original.iloc[val_index:]\n",
    "val_df = train_df_original.iloc[:val_index]\n",
    "\n",
    "y_train = train_df['Label']\n",
    "y_val = val_df['Label']\n",
    "y_test = test_df['Label']\n",
    "\n",
    "# Reshape the traing and test set to use them with a generator\n",
    "X_train = train_df.drop('Label',axis = 1).values.reshape(train_df.shape[0], 28, 28, 1)\n",
    "X_val = val_df.drop('Label',axis = 1).values.reshape(val_df.shape[0], 28, 28, 1)\n",
    "X_test = test_df.drop('Label',axis = 1).values.reshape(test_df.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the shapes of the sets\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                            rotation_range=10,\n",
    "                                                            zoom_range=0.10,\n",
    "                                                            width_shift_range=0.1,\n",
    "                                                            height_shift_range=0.1,\n",
    "                                                            shear_range=0.1,\n",
    "                                                            horizontal_flip=False,\n",
    "                                                            fill_mode=\"nearest\")\n",
    "\n",
    "X_train_flow = generator.flow(X_train, y_train, batch_size=32)\n",
    "X_val_flow = generator.flow(X_val, y_val, batch_size=32)\n",
    "# X_test_flow = generator.flow(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create and train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([Conv2D(filters=32,  kernel_size=(3,3), activation=\"relu\", input_shape=(28,28,1)),\n",
    "                    MaxPool2D(2,2, padding='same'),\n",
    "                    \n",
    "                    Conv2D(filters=128,  kernel_size=(3,3), activation=\"relu\"),\n",
    "                    MaxPool2D(2,2, padding='same'),\n",
    "                    \n",
    "                    Conv2D(filters=512, kernel_size=(3,3), activation=\"relu\"),\n",
    "                    MaxPool2D(2,2, padding='same'),\n",
    "                    \n",
    "                    Flatten(),\n",
    "                    \n",
    "                    Dense(units=1024, activation=\"relu\"),                 \n",
    "                    Dense(units=256, activation=\"relu\"),\n",
    "                    Dropout(0.5),\n",
    "                    Dense(units=25, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.5, min_lr=0.00001)\n",
    "\n",
    "history = model.fit(X_train_flow, \n",
    "                    validation_data=X_val_flow, \n",
    "                    epochs=100,\n",
    "                    callbacks=[\n",
    "                            tf.keras.callbacks.EarlyStopping(\n",
    "                            monitor='val_loss',\n",
    "                            patience=5,\n",
    "                            restore_best_weights=True), \n",
    "                        \n",
    "                            learning_rate_reduction\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize the result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "ax = axes.flat\n",
    "\n",
    "pd.DataFrame(history.history)[['accuracy','val_accuracy']].plot(ax=ax[0])\n",
    "ax[0].set_title(\"Accuracy\", fontsize = 15)\n",
    "ax[0].set_ylim(0,1.1)\n",
    "\n",
    "pd.DataFrame(history.history)[['loss','val_loss']].plot(ax=ax[1])\n",
    "ax[1].set_title(\"Loss\", fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the label of the test_images\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "# Get the accuracy score\n",
    "acc = accuracy_score(y_test,pred)\n",
    "\n",
    "# Display the results\n",
    "printmd(f'## {acc*100:.2f}% accuracy on the test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the numbers into letters\n",
    "y_test_letters = [mapping_letter[x] for x in y_test]\n",
    "pred_letters = [mapping_letter[x] for x in pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_letters,pred_letters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a confusion matrix\n",
    "cf_matrix = confusion_matrix(y_test_letters, pred_letters, normalize='true')\n",
    "plt.figure(figsize = (20,15))\n",
    "sns.heatmap(cf_matrix, annot=True, xticklabels = sorted(set(y_test_letters)), yticklabels = sorted(set(y_test_letters)),cbar=False)\n",
    "plt.title('Normalized Confusion Matrix\\n', fontsize = 23)\n",
    "plt.xlabel(\"Predicted Classes\",fontsize=15)\n",
    "plt.ylabel(\"True Classes\",fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15,rotation=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
